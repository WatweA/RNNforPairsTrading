{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from src.utils.finance_metrics import annualized_return\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Results for pair ('BAC', 'WFC'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 0.295929\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 100}\n",
      "  - MSE: 0.127596\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 75}\n",
      "  - MSE: 0.000072\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'exponential', 'n_estimators': 100}\n",
      "  - MSE: 0.042979\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 200}\n",
      "  - MSE: 0.000104\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (100, 25)}\n",
      "  - MSE: 0.004547\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.008218\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('HP', 'PTEN'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 1.515577\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.634391\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 100}\n",
      "  - MSE: 0.147045\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'linear', 'n_estimators': 200}\n",
      "  - MSE: 0.145538\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 150}\n",
      "  - MSE: 0.133831\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (150, 50)}\n",
      "  - MSE: 0.348300\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.230630\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('AEG', 'ING'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 0.508888\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.137337\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 75}\n",
      "  - MSE: 0.002368\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'linear', 'n_estimators': 150}\n",
      "  - MSE: 0.030526\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 150}\n",
      "  - MSE: 0.000398\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (100, 25)}\n",
      "  - MSE: 0.027550\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.009154\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('TDS', 'USM'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 0.375579\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.056882\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 50}\n",
      "  - MSE: 0.000081\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'linear', 'n_estimators': 100}\n",
      "  - MSE: 0.015097\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 200}\n",
      "  - MSE: 0.000117\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (150, 25)}\n",
      "  - MSE: 0.003728\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.003015\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('MRO', 'MUR'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 1.749834\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.478964\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 100}\n",
      "  - MSE: 0.053990\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'linear', 'n_estimators': 50}\n",
      "  - MSE: 0.053266\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 200}\n",
      "  - MSE: 0.039867\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (100, 25)}\n",
      "  - MSE: 0.244075\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.105475\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('AVB', 'EQR'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 0.369788\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.080227\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 50}\n",
      "  - MSE: 0.000916\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'linear', 'n_estimators': 200}\n",
      "  - MSE: 0.030388\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 200}\n",
      "  - MSE: 0.001533\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (100, 25)}\n",
      "  - MSE: 0.016291\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.009082\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('CMA', 'TFC'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 0.600942\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.199154\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 75}\n",
      "  - MSE: 0.017368\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'linear', 'n_estimators': 200}\n",
      "  - MSE: 0.035106\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 150}\n",
      "  - MSE: 0.015996\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (150, 50)}\n",
      "  - MSE: 0.068930\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.039221\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('FRT', 'REG'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 0.360837\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.046742\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 125}\n",
      "  - MSE: 0.000054\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'linear', 'n_estimators': 50}\n",
      "  - MSE: 0.019950\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 200}\n",
      "  - MSE: 0.000269\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (100, 25)}\n",
      "  - MSE: 0.007751\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.003415\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('CPT', 'UDR'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 0.364512\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.077727\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 75}\n",
      "  - MSE: 0.000522\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'linear', 'n_estimators': 200}\n",
      "  - MSE: 0.021802\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 200}\n",
      "  - MSE: 0.000706\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (150, 50)}\n",
      "  - MSE: 0.012858\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.006347\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('IAC', 'MTCH'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 30.528605\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 0.001}\n",
      "  - MSE: 30.566008\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 75}\n",
      "  - MSE: 16.588271\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'exponential', 'n_estimators': 150}\n",
      "  - MSE: 16.430321\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 150}\n",
      "  - MSE: 17.122917\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (100, 25)}\n",
      "  - MSE: 22.367605\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 19.666282\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('KBH', 'PHM'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 0.809095\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.258026\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 75}\n",
      "  - MSE: 0.016605\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'exponential', 'n_estimators': 50}\n",
      "  - MSE: 0.020536\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 100}\n",
      "  - MSE: 0.015366\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (150, 50)}\n",
      "  - MSE: 0.057009\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.038883\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('ED', 'SO'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 0.953335\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.257631\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 100}\n",
      "  - MSE: 0.032640\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'exponential', 'n_estimators': 200}\n",
      "  - MSE: 0.053334\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 200}\n",
      "  - MSE: 0.024917\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (150, 25)}\n",
      "  - MSE: 0.077606\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.057366\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('RMT', 'RVT'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 0.254652\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.077546\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 125}\n",
      "  - MSE: 0.002572\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'exponential', 'n_estimators': 150}\n",
      "  - MSE: 0.013424\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 150}\n",
      "  - MSE: 0.002573\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (150, 50)}\n",
      "  - MSE: 0.006438\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.008260\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('IFN', 'IIF'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 0.299216\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.047456\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 75}\n",
      "  - MSE: 0.000039\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'linear', 'n_estimators': 200}\n",
      "  - MSE: 0.016390\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 150}\n",
      "  - MSE: 0.000221\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (150, 25)}\n",
      "  - MSE: 0.010323\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.003116\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('BEN', 'TROW'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 0.629912\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.180585\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 100}\n",
      "  - MSE: 0.002776\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'linear', 'n_estimators': 150}\n",
      "  - MSE: 0.013990\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 150}\n",
      "  - MSE: 0.003776\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (150, 50)}\n",
      "  - MSE: 0.062953\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.007866\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('GOLD', 'NEM'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 0.875145\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.153852\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 50}\n",
      "  - MSE: 0.000576\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'exponential', 'n_estimators': 50}\n",
      "  - MSE: 0.009574\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 100}\n",
      "  - MSE: 0.001398\n",
      "--------------------------------------------------\n",
      "- Model: Neural Net\n",
      "  - best parameters: {'hidden_layer_sizes': (100, 25)}\n",
      "  - MSE: 0.072171\n",
      "--------------------------------------------------\n",
      "- Ensemble of all models\n",
      "  - MSE: 0.008393\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Results for pair ('COP', 'PEO'):\n",
      "- Model: Linear Regression\n",
      "  - best parameters: {'l1_ratio': 0.1}\n",
      "  - MSE: 1.368161\n",
      "--------------------------------------------------\n",
      "- Model: Support Vector Machine\n",
      "  - best parameters: {'C': 10}\n",
      "  - MSE: 0.418611\n",
      "--------------------------------------------------\n",
      "- Model: Random Forest\n",
      "  - best parameters: {'n_estimators': 50}\n",
      "  - MSE: 0.052366\n",
      "--------------------------------------------------\n",
      "- Model: Adaptive Boost\n",
      "  - best parameters: {'base_estimator': DecisionTreeRegressor(max_depth=3), 'loss': 'exponential', 'n_estimators': 150}\n",
      "  - MSE: 0.076043\n",
      "--------------------------------------------------\n",
      "- Model: Gradient Boost\n",
      "  - best parameters: {'n_estimators': 150}\n",
      "  - MSE: 0.050142\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-cf119e5dea61>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0mpred_average\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mmodel_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpair\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m         \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0mpred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmodel_type\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m\"Linear Regression\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/RNNforPairsTrading/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/RNNforPairsTrading/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    878\u001B[0m             \u001B[0mrefit_start_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    879\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0my\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 880\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_estimator_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    881\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    882\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_estimator_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/RNNforPairsTrading/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    671\u001B[0m         \u001B[0mself\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0mreturns\u001B[0m \u001B[0ma\u001B[0m \u001B[0mtrained\u001B[0m \u001B[0mMLP\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    672\u001B[0m         \"\"\"\n\u001B[0;32m--> 673\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mincremental\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    674\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    675\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/RNNforPairsTrading/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001B[0m in \u001B[0;36m_fit\u001B[0;34m(self, X, y, incremental)\u001B[0m\n\u001B[1;32m    402\u001B[0m         \u001B[0;31m# Run the LBFGS solver\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    403\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msolver\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'lbfgs'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 404\u001B[0;31m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001B[0m\u001B[1;32m    405\u001B[0m                             intercept_grads, layer_units)\n\u001B[1;32m    406\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/RNNforPairsTrading/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001B[0m in \u001B[0;36m_fit_lbfgs\u001B[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001B[0m\n\u001B[1;32m    488\u001B[0m             \u001B[0miprint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    489\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 490\u001B[0;31m         opt_res = scipy.optimize.minimize(\n\u001B[0m\u001B[1;32m    491\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_loss_grad_lbfgs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpacked_coef_inter\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    492\u001B[0m                 \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"L-BFGS-B\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjac\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/RNNforPairsTrading/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001B[0m in \u001B[0;36mminimize\u001B[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[1;32m    617\u001B[0m                                   **options)\n\u001B[1;32m    618\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mmeth\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'l-bfgs-b'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 619\u001B[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001B[0m\u001B[1;32m    620\u001B[0m                                 callback=callback, **options)\n\u001B[1;32m    621\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mmeth\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'tnc'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/RNNforPairsTrading/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001B[0m in \u001B[0;36m_minimize_lbfgsb\u001B[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001B[0m\n\u001B[1;32m    349\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    350\u001B[0m         \u001B[0;31m# x, f, g, wa, iwa, task, csave, lsave, isave, dsave = \\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 351\u001B[0;31m         _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n\u001B[0m\u001B[1;32m    352\u001B[0m                        \u001B[0mpgtol\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwa\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miwa\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miprint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcsave\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlsave\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    353\u001B[0m                        isave, dsave, maxls)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "data_path = r'data/processed'\n",
    "data_filenames = os.listdir(data_path)\n",
    "\n",
    "models = {}\n",
    "feature_scalers = {}\n",
    "target_scalers = {}\n",
    "for data_file in data_filenames:\n",
    "    pairs = data_file[:-4].split('-')\n",
    "    pair = (pairs[0], pairs[1])\n",
    "\n",
    "    pair_df = pd.read_pickle(os.path.join(data_path, data_file))\n",
    "    X = pair_df.loc[\"2000-01-01\":\"2014-12-31\", :].drop(columns=\"Return Diff (t+1)\")\n",
    "    y = pair_df.loc[\"2000-01-01\":\"2014-12-31\", [\"Return Diff (t+1)\"]]\n",
    "    X_test = pair_df.loc[\"2015-01-01\":, :].drop(columns=\"Return Diff (t+1)\")\n",
    "    y_test = pair_df.loc[\"2015-01-01\":, [\"Return Diff (t+1)\"]]\n",
    "\n",
    "    # scale with QuantileTransformer and StandardScaler\n",
    "    X_scaler = QuantileTransformer()\n",
    "    X_scaler.fit(X); feature_scalers[pair] = X_scaler\n",
    "    X_train = pd.DataFrame(X_scaler.transform(X), index=X.index, columns=X.columns)\n",
    "    X_test = pd.DataFrame(X_scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "    y_scaler = StandardScaler()\n",
    "    y_scaler.fit(y); target_scalers[pair] = y_scaler\n",
    "    y_train = pd.DataFrame(y_scaler.transform(y), index=y.index, columns=y.columns)\n",
    "    y_test = pd.DataFrame(y_scaler.transform(y_test), index=y_test.index, columns=y_test.columns)\n",
    "    assert False == any([any(arr) for arr in np.array(np.isinf(X_train))])\n",
    "    assert False == any([any(arr) for arr in np.array(np.isnan(X_train))])\n",
    "    assert False == any([any(arr) for arr in np.array(np.isinf(X_test))])\n",
    "    assert False == any([any(arr) for arr in np.array(np.isnan(X_test))])\n",
    "    assert False == any([any(arr) for arr in np.array(np.isinf(y_train))])\n",
    "    assert False == any([any(arr) for arr in np.array(np.isnan(y_train))])\n",
    "    assert False == any([any(arr) for arr in np.array(np.isinf(y_test))])\n",
    "    assert False == any([any(arr) for arr in np.array(np.isnan(y_test))])\n",
    "\n",
    "    split = PredefinedSplit(test_fold=[0 if v else -1 for v in X_train.index < '2012-01-01'])\n",
    "    models[(pairs[0], pairs[1])] = {\n",
    "        'Linear Regression': GridSearchCV(estimator=ElasticNet(max_iter=100000, tol=0.0004), param_grid={\n",
    "            'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "        }, cv=split, scoring=\"explained_variance\", n_jobs=-1),\n",
    "        'Support Vector Machine': GridSearchCV(estimator=SVR(cache_size=1000), param_grid={\n",
    "            'C': [10**n for n in range(-3, 4)]\n",
    "        }, cv=split, scoring=\"explained_variance\", n_jobs=-1),\n",
    "        'Random Forest': GridSearchCV(estimator=RandomForestRegressor(bootstrap=True), param_grid={\n",
    "            \"n_estimators\": [n for n in range(50, 150, 25)]\n",
    "        }, cv=split, scoring=\"explained_variance\", n_jobs=-1),\n",
    "        'Adaptive Boost': GridSearchCV(estimator=AdaBoostRegressor(), param_grid={\n",
    "            \"base_estimator\": [DecisionTreeRegressor(max_depth=1), DecisionTreeRegressor(max_depth=3)],\n",
    "            \"n_estimators\": [n for n in range(50, 250, 50)],\n",
    "            \"loss\": [\"linear\", \"exponential\"]\n",
    "        }, cv=split, scoring=\"explained_variance\", n_jobs=-1),\n",
    "        'Gradient Boost': GridSearchCV(estimator=GradientBoostingRegressor(loss=\"huber\"), param_grid={\n",
    "            \"n_estimators\": [n for n in range(50, 250, 50)]\n",
    "        }, cv=split, scoring=\"explained_variance\", n_jobs=-1),\n",
    "        'Neural Net': GridSearchCV(estimator=MLPRegressor(solver=\"lbfgs\", max_iter=1000000), param_grid={\n",
    "            \"hidden_layer_sizes\": [(h1, h2)\n",
    "                                   for h1 in range(100, 200, 50)\n",
    "                                   for h2 in range(25, h1//2, 25)]\n",
    "        }, cv=split, scoring=\"explained_variance\", n_jobs=-1)\n",
    "    }\n",
    "\n",
    "    print(f\"==================================================\\n\"\n",
    "          f\"Results for pair {pair}:\")\n",
    "    pred_average = None\n",
    "    for model_type, model in models[pair].items():\n",
    "        model.fit(X_train, np.array(y_train).ravel())\n",
    "        pred = model.predict(X_test)\n",
    "        if model_type != \"Linear Regression\":\n",
    "            if pred_average is None: pred_average = pred / 5\n",
    "            else: pred_average = pred_average + np.array(pred / 5)\n",
    "        mse = mean_squared_error(np.array(y_test), np.array(pred).ravel())\n",
    "        print(f\"- Model: {model_type}\\n\"\n",
    "              f\"  - best parameters: {model.best_params_}\\n\"\n",
    "              f\"  - MSE: {mse:.06f}\\n\"\n",
    "              f\"--------------------------------------------------\")\n",
    "    mse = mean_squared_error(np.array(y_test), np.array(pred_average).ravel())\n",
    "    print(f\"- Ensemble of all models\\n\"\n",
    "          f\"  - MSE: {mse:.06f}\\n\"\n",
    "          f\"--------------------------------------------------\")\n",
    "    print(f\"==================================================\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-9d37a789",
   "language": "python",
   "display_name": "PyCharm (RNNforPairsTrading)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}