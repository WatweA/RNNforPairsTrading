{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import OrderedDict, defaultdict\n",
    "import json  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = sorted([ticker[9:-4] for ticker in glob.glob(\"data/raw/*.zip\")])\n",
    "daily_returns = pd.DataFrame(index=pd.date_range(start=\"1999-01-05\", end=\"2021-03-01\", \n",
    "                                                 freq=pd.tseries.offsets.BDay(), name=\"Date\"))  # business dates\n",
    "for ticker in tickers:\n",
    "    df = pd.read_pickle(\"data/raw/\" + ticker + \".zip\")  # needs pickle5 compression (python 3.8)\n",
    "    daily_returns[ticker] = df[\"Log Return\"].fillna(method='ffill')\n",
    "\n",
    "daily_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GENERATES A HEATMAP OF CORRELATIONS\n",
    "# but its not useful since we have 1846x1846 correlations\n",
    "# just uncomment everything once to try it out\n",
    "\n",
    "# vegetables = tickers\n",
    "# farmers = tickers\n",
    "\n",
    "# harvest = daily_returns.corr(method=\"pearson\")\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# im = ax.imshow(harvest)\n",
    "\n",
    "# # We want to show all ticks...\n",
    "# # ax.set_xticks(np.arange(len(farmers)))\n",
    "# # ax.set_yticks(np.arange(len(vegetables)))\n",
    "# # ... and label them with the respective list entries\n",
    "# # ax.set_xticklabels(farmers)\n",
    "# # ax.set_yticklabels(vegetables)\n",
    "\n",
    "# # Rotate the tick labels and set their alignment.\n",
    "# plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "#          rotation_mode=\"anchor\")\n",
    "\n",
    "# # Loop over data dimensions and create text annotations.\n",
    "# for i in range(len(vegetables)):\n",
    "#     for j in range(len(farmers)):\n",
    "#         text = ax.text(j, i, harvest[i, j],\n",
    "#                        ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "# ax.set_title(\"Harvest of local farmers (in tons/year)\")\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = daily_returns.corr(method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 0.834 #highest threshold for 20 pairs\n",
    "\n",
    "def add_value(pairs_dict, key, value):\n",
    "    if key in pairs_dict.keys():\n",
    "        pairs_dict[key] += [value]\n",
    "    else:\n",
    "        pairs_dict[key] = [value]\n",
    "\n",
    "def get_top_pairs(useThreshold):\n",
    "    pairs_dict = {}\n",
    "    for ticker in tickers:\n",
    "        top5 = corr.sort_values(by=[ticker])[ticker][-6:-1] # exclude itself\n",
    "        assert top5.name == ticker\n",
    "\n",
    "        # TOP 5 FOR EVERY TICKER\n",
    "        if not useThreshold:\n",
    "            pairs_dict[ticker] = top5.to_dict({})\n",
    "            \n",
    "        # JUST ADD THOSE ABOVE THRESHOLD\n",
    "        else:\n",
    "            if top5.max() > th:\n",
    "                for tick in top5.index:\n",
    "                    if top5[tick] > th:\n",
    "                        add_value(pairs_dict, top5.name, {tick: top5[tick]})\n",
    "                \n",
    "    return pairs_dict\n",
    "\n",
    "\n",
    "def top_n_pairs(n: int=5) -> Dict[str, Dict[str, float]]:\n",
    "    pairs_dict: Dict[str, Dict[str, float]]=dict()\n",
    "    for ticker in tickers:\n",
    "        top_n = corr.sort_values(by=[ticker])[ticker][(-1 - n):-1] # exclude itself\n",
    "        assert top_n.name == ticker\n",
    "        pairs_dict[ticker] = top_n.to_dict({})\n",
    "    \n",
    "    return pairs_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5alltickers = get_top_pairs(False)\n",
    "top20pairs = get_top_pairs(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVES THE JSON TO THE DESIRED PATH\n",
    "top5alltickersJSON = json.dumps(top5alltickers, sort_keys=False, indent=4, separators=(',', ': '))\n",
    "save_path = \"data/info/corellations.json\"\n",
    "open(save_path,\"w\").write(top5alltickersJSON)\n",
    "print(top5alltickersJSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVES THE JSON TO THE DESIRED PATH\n",
    "top20pairsJSON = json.dumps(top20pairs, sort_keys=False, indent=4, separators=(',', ': '))\n",
    "save_path = \"data/info/top20corellations.json\"\n",
    "open(save_path,\"w\").write(top20pairsJSON)\n",
    "print(top20pairsJSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "def match_tickers(corr_dict: Dict[str, Dict[str, float]], min_corr=0, debug=False):\n",
    "    all_tickers: Set[str] = set()\n",
    "    all_pairs: Dict[Tuple[str, str], float] = dict()\n",
    "    # iterate over all pairs, and add the SORTED tuple of tickers with their correlations\n",
    "    # sorting ensures (A, B) and (B, A) will not both be added\n",
    "    for ticker_a, ticker_a_dict in corr_dict.items():\n",
    "        for ticker_b, a_b_corr in ticker_a_dict.items():\n",
    "            # for ticker pairs above the minimum corr, add to the set and dict\n",
    "            if min_corr <= a_b_corr:\n",
    "                all_tickers.add(ticker_a); all_tickers.add(ticker_b)\n",
    "                all_pairs[tuple(sorted([ticker_a, ticker_b]))] = a_b_corr\n",
    "    \n",
    "    # use a modified non-optimal version of Gale-Shapley to find the matchings\n",
    "    unmatched: Dict[str, bool] = {ticker: True for ticker in all_tickers}\n",
    "    matches: Dict[str, str] = dict()  # use dict instead of list of sets for speed\n",
    "    i = 0  # terminate at 100 iterations\n",
    "    while any([unmatched_i for unmatched_i in unmatched.values()]) and i < 100:\n",
    "        if debug:\n",
    "            num_matched = sum([1 for unmatched_i in unmatched.values() if not unmatched_i])\n",
    "            print(f\"Iteration: {i}, number matched: {num_matched}\")\n",
    "        for (ticker_a, ticker_b), a_b_corr in all_pairs.items():\n",
    "            if unmatched[ticker_a] and unmatched[ticker_b]:\n",
    "                unmatched[ticker_a] = False; unmatched[ticker_b] = False\n",
    "                matches[ticker_a] = ticker_b; matches[ticker_b] = ticker_a\n",
    "            else:\n",
    "                a_pair = tuple(sorted([ticker_a, matches.get(ticker_a, \"\")]))\n",
    "                b_pair = tuple(sorted([ticker_b, matches.get(ticker_b, \"\")]))\n",
    "                a_corr = all_pairs.get(a_pair, 0.0)\n",
    "                b_corr = all_pairs.get(b_pair, 0.0)\n",
    "                # if tickers a and b are better corellated than their current matches\n",
    "                if a_corr < a_b_corr and b_corr < a_b_corr:\n",
    "                    if debug: \n",
    "                        print(f\"pair: {(ticker_a, ticker_b)} better than {a_pair} and {b_pair}\")\n",
    "                    # remove the current matches (checking if they exist)\n",
    "                    ticker_a_match = matches.get(ticker_a, \"\")\n",
    "                    ticker_b_match = matches.get(ticker_b, \"\")\n",
    "                    if ticker_a_match != \"\": \n",
    "                        unmatched[ticker_a_match] = True\n",
    "                        del matches[ticker_a_match]\n",
    "                    if ticker_b_match != \"\": \n",
    "                        unmatched[ticker_b_match] = True\n",
    "                        del matches[ticker_b_match]\n",
    "                    \n",
    "                    # match ticker_a and ticker_b\n",
    "                    unmatched[ticker_a] = False; unmatched[ticker_b] = False\n",
    "                    matches[ticker_a] = ticker_b; matches[ticker_b] = ticker_a\n",
    "        i += 1\n",
    "    \n",
    "    matched_pairs: Dict[Tuple[str, str], float] = {\n",
    "        tuple(sorted([ticker_a, ticker_b])): all_pairs.get(tuple(sorted([ticker_a, ticker_b])))\n",
    "        for (ticker_a, ticker_b) in matches.items()\n",
    "    }\n",
    "    return matched_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_tickers = match_tickers(top5alltickers, min_corr=0.75)\n",
    "# tuple to tuple string representation for keys, save as JSON\n",
    "matched_tickers_JSON = json.dumps(\n",
    "    {str(k): v for k,v in matched_tickers.items()}, \n",
    "    sort_keys=False, indent=4, separators=(',', ': '))\n",
    "save_path = \"data/info/pairs.json\"\n",
    "open(save_path,\"w\").write(matched_tickers_JSON)\n",
    "print(matched_tickers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
